{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jdtkbtMebKyP"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO7WZdYPySvfcTvEwkybRvM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tobiaskatsch/LinearRNN/blob/master/log_quadratic_ssm_equality_check.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log/Quadratic SSM Equality Check"
      ],
      "metadata": {
        "id": "EIn4bak_bPha"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T_3qdPQ4HjK1"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as jnp\n",
        "from jax.lax import associative_scan\n",
        "from flax import linen as nn\n",
        "from jax import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MaxHead Equality Check"
      ],
      "metadata": {
        "id": "jdtkbtMebKyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def max_heads_quadratic(q, k, v, amplitude, phase):\n",
        "    # inputs: batchsize x seq_len x d\n",
        "    b, l, d = q.shape\n",
        "    q = q.reshape(b, l, d, 1).transpose((0, 2, 1, 3))\n",
        "    k = k.reshape(b, l, d, 1).transpose((0, 2, 1, 3))\n",
        "    v = v.reshape(b, l, d, 1).transpose((0, 2, 1, 3))\n",
        "    amplitude = amplitude.reshape(b, l, d, 1).transpose((0, 2, 1, 3))\n",
        "    phase = phase.reshape(b, l, d, 1).transpose((0, 2, 1, 3))\n",
        "    # b, d, l, 1\n",
        "\n",
        "    cum_amplitude = jnp.cumprod(amplitude, axis=2)\n",
        "    cum_phase = jnp.cumsum(phase, axis=2)\n",
        "    q = q * cum_amplitude * jnp.exp(1j * cum_phase)\n",
        "    k = k * (1/cum_amplitude) * jnp.exp((-1) * 1j * cum_phase)\n",
        "    scores = jnp.matmul(q, k.transpose((0, 1, 3, 2)))\n",
        "\n",
        "    causal_mask = jnp.tril(jnp.ones((l, l), dtype=bool)).reshape((1, 1, l, l))\n",
        "    scores = jnp.where(causal_mask, scores, 0.)\n",
        "\n",
        "    y = jnp.matmul(scores, v)\n",
        "    y = y.reshape((batch_size, seq_len, d))\n",
        "    return y\n",
        "\n",
        "\n",
        "def max_heads_logarithmic(q, k, v, amplitude, phase):\n",
        "    # inputs: batchsize x seq_len x head_size\n",
        "\n",
        "    def binary_operator(e_i, e_j):\n",
        "        a_i, vk_i = e_i\n",
        "        a_j, vk_j = e_j\n",
        "        return a_j * a_i, a_j * vk_i + vk_j\n",
        "\n",
        "    a = amplitude * jnp.exp(1j * phase)\n",
        "    vk = v * k\n",
        "    _, y = associative_scan(binary_operator, (a, vk), axis=1)\n",
        "    y = y * q\n",
        "    return y"
      ],
      "metadata": {
        "id": "Hi7XmoxUGcmE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_experiments = 10\n",
        "tolerance = 1000  # Define your tolerance level\n",
        "\n",
        "for i in range(n_experiments):\n",
        "    # Create random seed\n",
        "    key = random.PRNGKey(i)\n",
        "\n",
        "    # Generate complex random arrays for q, k, and v\n",
        "    batch_size, seq_len, d = 32, 50, 128\n",
        "\n",
        "    q = random.normal(key, (batch_size, seq_len, d)) + 1j * random.normal(key, (batch_size, seq_len, d))\n",
        "    k = random.normal(key, (batch_size, seq_len, d)) + 1j * random.normal(key, (batch_size, seq_len, d))\n",
        "    v = random.normal(key, (batch_size, seq_len, d)) + 1j * random.normal(key, (batch_size, seq_len, d))\n",
        "\n",
        "    # Generate random real-valued arrays for amplitude and phase\n",
        "    amplitude_raw = random.normal(key, (batch_size, seq_len, d))\n",
        "    phase_raw = random.normal(key, (batch_size, seq_len, d))\n",
        "\n",
        "    # Apply non-linearities\n",
        "    amplitude = nn.sigmoid(amplitude_raw)\n",
        "    phase = nn.relu(phase_raw)\n",
        "\n",
        "    # Calculate the output from the quadratic function\n",
        "    output1 = max_heads_quadratic(q, k, v, amplitude, phase)\n",
        "    output2 = max_heads_logarithmic(q, k, v, amplitude, phase)\n",
        "\n",
        "    # Check if the outputs are close enough to be considered equal\n",
        "    if jnp.allclose(output1, output2, atol=tolerance):\n",
        "        print(f\"Experiment {i+1}: Equal\", jnp.mean(output1), \"=\", jnp.mean(output2))\n",
        "    else:\n",
        "        print(f\"Experiment {i+1}: Not Equal\", jnp.mean(output1), \"!=\", jnp.mean(output2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pv3eUf38KFvF",
        "outputId": "d6b82441-85e3-43ac-dc2e-335da5116de8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 1: Equal (-0.31757334-0.88877857j) = (-0.31757346-0.8887784j)\n",
            "Experiment 2: Equal (-0.3013515-0.90275556j) = (-0.30135155-0.9027553j)\n",
            "Experiment 3: Equal (-0.3124598-0.90063137j) = (-0.31246015-0.90063125j)\n",
            "Experiment 4: Equal (-0.315858-0.9025356j) = (-0.31585807-0.9025354j)\n",
            "Experiment 5: Equal (-0.3459811-0.8823404j) = (-0.3459812-0.88234013j)\n",
            "Experiment 6: Equal (-0.30827466-0.9041539j) = (-0.30827454-0.9041537j)\n",
            "Experiment 7: Equal (-0.30112782-0.90319335j) = (-0.3011277-0.9031928j)\n",
            "Experiment 8: Equal (-0.3496565-0.86219275j) = (-0.34965613-0.86219305j)\n",
            "Experiment 9: Equal (-0.31240523-0.8952814j) = (-0.31240538-0.8952817j)\n",
            "Experiment 10: Equal (-0.3331844-0.87800854j) = (-0.33318472-0.8780085j)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discussion: (with set parameters) l < 50 leads to equal results for both variants but increasing l >= 100 leads to nan occuring in the quadratic variant. This happens due to the extreme values 1/cum_amp and cum_amp assume. Clipping of the amplitude does not help definitively: For instance a chain of data controlled 0.5 amplitude can also cause this."
      ],
      "metadata": {
        "id": "YtJrgReiVuRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arbirary Headed"
      ],
      "metadata": {
        "id": "QX58nSI-f0uN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def arbitrary_heads_quadratic(q, k, v, amplitude, phase):\n",
        "    b, l, h, d_qk = q.shape\n",
        "    d_v = v.shape[3]\n",
        "\n",
        "    q = q.transpose((0, 2, 1, 3))\n",
        "    k = k.transpose((0, 2, 1, 3))\n",
        "    v = v.transpose((0, 2, 1, 3))\n",
        "    amplitude = amplitude.transpose((0, 2, 1, 3))\n",
        "    phase = phase.transpose((0, 2, 1, 3))\n",
        "    # b, h, l, d\n",
        "\n",
        "    cum_amplitude = jnp.cumprod(amplitude, axis=2)\n",
        "    cum_phase = jnp.cumsum(phase, axis=2)\n",
        "    q = q * cum_amplitude * jnp.exp(1j * cum_phase)\n",
        "    k = k * (1/cum_amplitude) * jnp.exp((-1) * 1j * cum_phase)\n",
        "    k = k.transpose((0, 1, 3, 2)) # b, h, d, l\n",
        "    scores = jnp.matmul(q, k)\n",
        "\n",
        "    causal_mask = jnp.tril(jnp.ones((l, l), dtype=bool)).reshape((1, 1, l, l))\n",
        "    scores = jnp.where(causal_mask, scores, 0.)\n",
        "\n",
        "    y = jnp.matmul(scores, v)\n",
        "    y = y.reshape((batch_size, seq_len, d_v*h))\n",
        "    return y\n",
        "\n",
        "\n",
        "def arbitrary_heads_logarithmic(q, k, v, amplitude, phase):\n",
        "    b, l, h, d_qk = q.shape\n",
        "    d_v = v.shape[3]\n",
        "    a = amplitude * jnp.exp(1j * phase)\n",
        "    k = k.reshape(b, l, h, d_qk, 1)\n",
        "    q = q.reshape(b, l, h, d_qk, 1).transpose((0, 1, 2, 4, 3))\n",
        "    v = v.reshape(b, l, h, d_v, 1).transpose((0, 1, 2, 4, 3))\n",
        "    a = a.reshape(b, l, h, d_qk, 1)\n",
        "\n",
        "    def binary_operator(e_i, e_j):\n",
        "        a_i, kv_i = e_i\n",
        "        a_j, kv_j = e_j\n",
        "        return a_j * a_i, a_j * kv_i + kv_j\n",
        "\n",
        "    kv = jnp.matmul(k, v)\n",
        "    _, y = associative_scan(binary_operator, (a, kv), axis=1)\n",
        "    y = jnp.matmul(q, y)\n",
        "    y = y.reshape((batch_size, seq_len, d_v*h))\n",
        "    return y"
      ],
      "metadata": {
        "id": "8bGS8xuNf0PJ"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_experiments = 10\n",
        "tolerance = 1000  # Define your tolerance level\n",
        "\n",
        "for i in range(n_experiments):\n",
        "    # Create random seed\n",
        "    key = random.PRNGKey(i+1)\n",
        "\n",
        "    # Generate complex random arrays for q, k, and v\n",
        "    batch_size, seq_len, n_head, qk_head_dim, v_head_dim = 32, 50, 4, 16, 32\n",
        "\n",
        "    q = random.normal(key, (batch_size, seq_len, n_head, qk_head_dim)) + 1j * random.normal(key, (batch_size, seq_len, n_head, qk_head_dim))\n",
        "    k = random.normal(key, (batch_size, seq_len, n_head, qk_head_dim)) + 1j * random.normal(key, (batch_size, seq_len, n_head, qk_head_dim))\n",
        "    v = random.normal(key, (batch_size, seq_len, n_head, v_head_dim)) + 1j * random.normal(key, (batch_size, seq_len, n_head, v_head_dim))\n",
        "\n",
        "    # Generate random real-valued arrays for amplitude and phase\n",
        "    amplitude_raw = random.normal(key, (batch_size, seq_len, n_head, qk_head_dim))\n",
        "    phase_raw = random.normal(key, (batch_size, seq_len, n_head, qk_head_dim))\n",
        "\n",
        "    # Apply non-linearities\n",
        "    amplitude = nn.sigmoid(amplitude_raw)\n",
        "    phase = nn.relu(phase_raw)\n",
        "\n",
        "    # Calculate the output from the quadratic function\n",
        "    output1 = arbitrary_heads_quadratic(q, k, v, amplitude, phase)\n",
        "    output2 = arbitrary_heads_logarithmic(q, k, v, amplitude, phase)\n",
        "\n",
        "    # Check if the outputs are close enough to be considered equal\n",
        "    if jnp.allclose(output1, output2, atol=tolerance):\n",
        "        print(f\"Experiment {i+1}: Equal\", jnp.mean(output1), \"=\", jnp.mean(output2))\n",
        "    else:\n",
        "        print(f\"Experiment {i+1}: Not Equal\", jnp.mean(output1), \"!=\", jnp.mean(output2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Go-lJWLgmYK",
        "outputId": "8d2becac-97f8-4164-9c17-c253c3f8248d"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 1: Equal (0.0675754-0.08274143j) = (0.06757529-0.082741104j)\n",
            "Experiment 2: Equal (0.032447454-0.044066206j) = (0.032447353-0.04406624j)\n",
            "Experiment 3: Equal (-0.022365812+0.0092469j) = (-0.022365859+0.009246964j)\n",
            "Experiment 4: Equal (-0.15796396+0.18204387j) = (-0.15796399+0.18204357j)\n",
            "Experiment 5: Equal (0.07056659-0.056545787j) = (0.07056679-0.056545563j)\n",
            "Experiment 6: Equal (0.07971294-0.077598445j) = (0.079712816-0.077598415j)\n",
            "Experiment 7: Equal (-0.15902089+0.16834456j) = (-0.15902093+0.16834445j)\n",
            "Experiment 8: Equal (-0.0872801+0.122678354j) = (-0.08728004+0.12267854j)\n",
            "Experiment 9: Equal (-0.052648935+0.018602788j) = (-0.052648906+0.018603094j)\n",
            "Experiment 10: Equal (0.050002463-0.071236655j) = (0.050002534-0.07123652j)\n"
          ]
        }
      ]
    }
  ]
}